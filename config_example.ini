[zhipu]
    api_key = 
    model = glm-3-turbo
    max_tokens = 800
    temperature = 0.9
    top_p = 0.7
    system = 
    # 开启后，提示词token几乎会增加到max_tokens上限，但回答质量还算可观
    use_web_search = false

[azure_openai]
    api_end_point = 
    deply_name = 
    api_version = 2024-02-01
    api_key = 
    # Azure OpenAI默认TPS是1000
    max_tokens = 300
    temperature = 0.7
    top_p = 0.7
    system = 

[bianxieai_openai]

[ernie]
    # model在api文档的请求地址的最后一段https://cloud.baidu.com/doc/WENXINWORKSHOP/s/dltgsna1o
    free_model = ernie-lite-8k
    model = completions
    api_key = 
    secret_key = 
    # 鉴权方式，可选access_token或sign（基于安全认证、签名）的方式，后者暂未实现
    auth_method = access_token
    temperature = 0.95
    top_p = 0.7
    penalty_score = 1
    max_output_tokens = 2048
    system = 
    # 开启后，返回内容会加上参考资料的角标，免费版不支持联网查询，所以没用
    enable_citation = true
    # 开启后，会返回参考资料的search_info列表，免费版不支持
    enable_trace = true

[spark]
    appid = 
    api_secret = 
    api_key = 
    # Pro版wss://spark-api.xf-yun.com/v3.1/chat
    # Max版wss://spark-api.xf-yun.com/v3.5/chat
    url = wss://spark-api.xf-yun.com/v1.1/chat
    # Pro版generalv3
    # Max版generalv3.5
    domain = general
    # 取值(0,1)
    temperature = 0.5 
    # 最大4096
    max_tokens = 4096
    # 取值1,2,3,4,5,6
    top_k = 4
    system = 

[qwen]
    api_key = 
    # 模型，qwen-long、qwen-max、qwen-plus、qwen1.5-110b-chat等，详见阿里云百炼模型广场
    # 最便宜的qwen-long，没有网络搜索能力
    model = qwen-long
    # 带网络搜索能力的模型，网络搜索会增加提示词token的消耗
    model_search = qwen-turbo
    # 参考 https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope/?spm=a2c4g.11186623.0.0.25134ad0n6mRiV#341800c1f8h93
    # 摸了，用openai兼容接口
    url = https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
    top_p = 0.8
    temperature = 1.0
    max_tokens = 2000
    system = 

[deepseek]
    #==================== start 深度求索官方api ======================
    # 模型，deepseek-chat或deepseek-reasoner，后者为推理模型。
    # 详见 https://api-docs.deepseek.com/zh-cn/quick_start/pricing
    # api_key = 
    # model = deepseek-chat
    # model_reasoner = deepseek-reasoner
    # url = https://api.deepseek.com/chat/completions
    #==================== end 深度求索官方api ======================
    
    #==================== start 腾讯云知识引擎原子能力 ======================
    api_key = 
    url = https://api.lkeap.cloud.tencent.com/v1/chat/completions
    model = deepseek-v3
    model_reasoner = deepseek-r1
    #==================== end 腾讯云知识引擎原子能力 ======================
    temperature = 1.3
    top_p = 1
    frequency_penalty = 0
    max_tokens = 8000
    presence_penalty = 0
    # response_format =  {"type": "text"}
    # stream = false
    system = 

